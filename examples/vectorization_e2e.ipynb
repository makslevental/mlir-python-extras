{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Welcome to `mlir-python-extras` enjoy your stay!\n",
    "\n",
    "more at https://github.com/makslevental/mlir-python-extras"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:45:29.673103Z",
     "start_time": "2025-05-15T22:45:18.737745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if running by yourself, you can use this instead\n",
    "# !pip install -q mlir-python-extras -f https://makslevental.github.io/wheels\n",
    "import os\n",
    "BRANCH = os.getenv(\"BRANCH\", \"main\")\n",
    "os.environ[\"SCRIPT_ADDRESS\"] = f\"https://raw.githubusercontent.com/makslevental/mlir-python-extras/refs/heads/{BRANCH}/scripts/get_latest_bindings.py\"\n",
    "!curl $SCRIPT_ADDRESS -o get_latest_bindings.py\n",
    "!latest_version=$(python get_latest_bindings.py \"none\") && pip install -q mlir_python_bindings==$latest_version -f https://makslevental.github.io/wheels\n",
    "!pip install -q git+https://github.com/makslevental/mlir-python-extras@$BRANCH\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  2421  100  2421    0     0  15636      0 --:--:-- --:--:-- --:--:-- 15720\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Boilerplate"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "import mlir.extras.types as T\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects.transform import any_op_t\n",
    "from mlir.dialects.transform.extras import named_sequence, apply_patterns\n",
    "from mlir.extras.util import find_ops\n",
    "from mlir.ir import StringAttr, UnitAttr\n",
    "\n",
    "# you need this to register the memref value caster\n",
    "# noinspection PyUnresolvedReferences\n",
    "import mlir.extras.dialects.ext.memref\n",
    "from mlir.extras.context import RAIIMLIRContext, ExplicitlyManagedModule\n",
    "from mlir.dialects.bufferization import LayoutMapOption\n",
    "from mlir.dialects.transform.vector import (\n",
    "    VectorContractLowering,\n",
    "    VectorMultiReductionLowering,\n",
    "    VectorTransferSplit,\n",
    "    VectorTransposeLowering,\n",
    ")\n",
    "from mlir.extras.dialects.ext import linalg\n",
    "from mlir.extras.dialects.ext.func import func\n",
    "from mlir.extras.dialects.ext.transform import (\n",
    "    match,\n",
    "    tile_to_scf_for,\n",
    "    get_parent_op,\n",
    "    transform_any_op_t,\n",
    ")\n",
    "from mlir.extras.dialects.ext import transform\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context"
   ],
   "metadata": {
    "id": "s-JTcrjo7tNK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ctx = RAIIMLIRContext()\n",
    "module = ExplicitlyManagedModule()"
   ],
   "metadata": {
    "id": "AGpWj9BzZLC_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kernel"
   ],
   "metadata": {
    "id": "qGcDtgkv71YB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "M, K, N = 2, 4, 6\n",
    "\n",
    "\n",
    "@func\n",
    "def matmul_tensors(\n",
    "    A: T.tensor(M, K, T.f32()),\n",
    "    B: T.tensor(K, N, T.f32()),\n",
    "    C: T.tensor(M, N, T.f32()),\n",
    "):\n",
    "    return linalg.matmul(A, B, C)\n",
    "\n",
    "@builtin.module(attrs={\"transform.target_tag\": StringAttr.get(\"payload\")})\n",
    "def payload():\n",
    "    matmul_tensors.emit(force=True)"
   ],
   "metadata": {
    "id": "7oQk4xJd72FI"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform schedule (based on [transform-e2e.mlir](https://github.com/llvm/llvm-project/blob/375bd2201ce0d2c76cb47a02c87b8ca5ba8a3509/mlir/test/Dialect/LLVM/transform-e2e.mlir))"
   ],
   "metadata": {
    "id": "a0vJZrpR74KB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@builtin.module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "def mod_transform():\n",
    "    @named_sequence(\"main\", [any_op_t()], [])\n",
    "    def main(module_op: any_op_t()):\n",
    "        matmul = match(module_op, ops=[\"linalg.matmul\"])\n",
    "        tiled_matmul, (_, _, inner_loop) = tile_to_scf_for(matmul, sizes=[2, 2, 2])\n",
    "        transform.structured.vectorize_children_and_apply_patterns(\n",
    "            get_parent_op(transform_any_op_t(), tiled_matmul, isolated_from_above=True)\n",
    "        )\n",
    "        new_mod = transform.bufferization.one_shot_bufferize(\n",
    "            module_op,\n",
    "            function_boundary_type_conversion=LayoutMapOption.IdentityLayoutMap,\n",
    "            bufferize_function_boundaries=True,\n",
    "        )\n",
    "\n",
    "        func_op = match(new_mod, ops=[\"func.func\"])\n",
    "\n",
    "        @apply_patterns(func_op)\n",
    "        def pats():\n",
    "            transform.apply_patterns.vector.lower_contraction(\n",
    "                lowering_strategy=VectorContractLowering.OuterProduct\n",
    "            )\n",
    "            transform.apply_patterns.vector.transfer_permutation_patterns()\n",
    "            transform.apply_patterns.vector.lower_multi_reduction(\n",
    "                lowering_strategy=VectorMultiReductionLowering.InnerParallel\n",
    "            )\n",
    "            transform.apply_patterns.vector.split_transfer_full_partial(\n",
    "                split_transfer_strategy=VectorTransferSplit.LinalgCopy\n",
    "            )\n",
    "            transform.apply_patterns.vector.transfer_to_scf(\n",
    "                max_transfer_rank=1, full_unroll=True\n",
    "            )\n",
    "            transform.apply_patterns.vector.lower_transfer(max_transfer_rank=1)\n",
    "            transform.apply_patterns.vector.lower_shape_cast()\n",
    "            transform.apply_patterns.vector.lower_transpose(\n",
    "                lowering_strategy=VectorTransposeLowering.Shuffle1D\n",
    "            )"
   ],
   "metadata": {
    "id": "EaBgGTIz72ci"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \"Finish\" the module"
   ],
   "metadata": {
    "id": "ADbabroS8ND2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "module = module.finish()\n",
    "print(module)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOsYXaW8QKC",
    "outputId": "f8592229-1d9b-4c52-9133-30fd52c2716d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vectorize (execute the transform schedule)"
   ],
   "metadata": {
    "id": "0xN5kNvZ8Tyf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorized_module = run_pipeline(\n",
    "    module,\n",
    "    pipeline=Pipeline().transform_interpreter(\n",
    "        entry_point=\"main\", debug_payload_root_tag=\"payload\"\n",
    "    ),\n",
    ")\n",
    "print(vectorized_module)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLwQLPD98Q4d",
    "outputId": "ecfa6c9a-15eb-40c7-df29-f43fcac02fbf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lower to CPU (through LLVM, based on [TestLowerToLLVM.cpp](https://github.com/makslevental/llvm-project/blob/f6643263631bcb0d191ef923963ac1a5ca9ac5fd/mlir/test/lib/Dialect/LLVM/TestLowerToLLVM.cpp#L44))"
   ],
   "metadata": {
    "id": "D_NURglF8ZZW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lower_to_llvm = (\n",
    "    Pipeline()\n",
    "    .Func(\n",
    "        Pipeline()\n",
    "        # Blanket-convert any remaining high-level vector ops to loops if any remain.\n",
    "        .convert_vector_to_scf()\n",
    "        # Blanket-convert any remaining linalg ops to loops if any remain.\n",
    "        .convert_linalg_to_loops()\n",
    "    )\n",
    "    # Blanket-convert any remaining affine ops if any remain.\n",
    "    .lower_affine()\n",
    "    # Convert SCF to CF (always needed).\n",
    "    .convert_scf_to_cf()\n",
    "    # Sprinkle some cleanups.\n",
    "    .canonicalize()\n",
    "    .cse()\n",
    "    # Convert vector to LLVM (always needed).\n",
    "    .convert_vector_to_llvm()\n",
    "    # Convert Math to LLVM (always needed).\n",
    "    .Func(Pipeline().convert_math_to_llvm())\n",
    "    # Expand complicated MemRef operations before lowering them.\n",
    "    .expand_strided_metadata()\n",
    "    # The expansion may create affine expressions. Get rid of them.\n",
    "    .lower_affine()\n",
    "    # Convert MemRef to LLVM (always needed).\n",
    "    .finalize_memref_to_llvm()\n",
    "    # Convert Func to LLVM (always needed).\n",
    "    .convert_func_to_llvm()\n",
    "    .convert_arith_to_llvm()\n",
    "    .convert_cf_to_llvm()\n",
    "    # Convert Index to LLVM (always needed).\n",
    "    .convert_index_to_llvm()\n",
    "    # Convert remaining unrealized_casts (always needed).\n",
    "    .reconcile_unrealized_casts()\n",
    ")\n",
    "\n",
    "backend = LLVMJITBackend()\n",
    "compiled_module = backend.compile(\n",
    "    find_ops(\n",
    "        vectorized_module.operation,\n",
    "        lambda x: \"transform.target_tag\" in x.attributes\n",
    "        and x.attributes[\"transform.target_tag\"].value == \"payload\",\n",
    "        single=True,\n",
    "    ),\n",
    "    kernel_name=matmul_tensors.__name__,\n",
    "    pipeline=lower_to_llvm,\n",
    ")\n",
    "print(compiled_module)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IoWjgc48bcn",
    "outputId": "39550464-fd37-4e6d-a257-e803b746d8de"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load, run, and compare against numpy"
   ],
   "metadata": {
    "id": "sOapyydH8n4h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = np.random.randint(0, 10, (M, K)).astype(np.float32)\n",
    "B = np.random.randint(0, 10, (K, N)).astype(np.float32)\n",
    "C = np.zeros((M, N), dtype=np.float32)\n",
    "\n",
    "backend.load(compiled_module).matmul_tensors_capi_wrapper(A, B, C)\n",
    "assert np.allclose(A @ B, C)"
   ],
   "metadata": {
    "id": "pOEC4Qgw8p9X"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
