{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Based on [transform-mma-sync-matmul-f16-f16-accum.mlir](https://github.com/llvm/llvm-project/blob/9cc2122bf5a81f7063c2a32b2cb78c8d615578a1/mlir/test/Integration/GPU/CUDA/TensorCore/sm80/transform-mma-sync-matmul-f16-f16-accum.mlir#L6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download mlir-python-bindings with CUDA support"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "BRANCH = os.getenv(\"BRANCH\", \"main\")\n",
    "os.environ[\"SCRIPT_ADDRESS\"] = f\"https://raw.githubusercontent.com/makslevental/mlir-python-extras/refs/heads/{BRANCH}/scripts/get_latest_bindings.py\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xh-QUDWiX-FD",
    "outputId": "6865a63a-daa4-4610-e33a-721d37c0211f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "curl $SCRIPT_ADDRESS -o get_latest_bindings.py\n",
    "latest_cuda_version=$(python get_latest_bindings.py \"cuda\") && pip install -q mlir_python_bindings==$latest_cuda_version -f https://makslevental.github.io/wheels\n",
    "pip install -q git+https://github.com/makslevental/mlir-python-extras@$BRANCH"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Boilerplate"
   ],
   "metadata": {
    "id": "OSATAYhg7pSZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlir.extras.types as T\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects.transform import any_op_t\n",
    "from mlir.dialects.transform.extras import named_sequence\n",
    "from mlir.dialects.transform.structured import MatchInterfaceEnum\n",
    "from mlir.ir import StringAttr, UnitAttr\n",
    "\n",
    "from mlir import _mlir_libs\n",
    "from mlir.extras.ast.canonicalize import canonicalize\n",
    "from mlir.extras.context import RAIIMLIRContext, ExplicitlyManagedModule\n",
    "from mlir.extras.dialects.ext import arith, memref, scf, gpu\n",
    "from mlir.extras.dialects.ext import linalg\n",
    "from mlir.extras.dialects.ext import transform\n",
    "from mlir.extras.dialects.ext.func import func\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n",
    "from mlir.extras.util import find_ops\n",
    "\n",
    "CUDA_RUNTIME_LIB_PATH = Path(_mlir_libs.__file__).parent / f\"libmlir_cuda_runtime.so\"\n",
    "assert CUDA_RUNTIME_LIB_PATH.exists()"
   ],
   "metadata": {
    "id": "_R-_0M5ZYO8p"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context"
   ],
   "metadata": {
    "id": "s-JTcrjo7tNK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ctx = RAIIMLIRContext()\n",
    "module = ExplicitlyManagedModule()"
   ],
   "metadata": {
    "id": "AGpWj9BzZLC_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kernel and helper code"
   ],
   "metadata": {
    "id": "qGcDtgkv71YB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "range_ = scf.range_\n",
    "\n",
    "M, K, N = 16, 16, 8\n",
    "\n",
    "# forward reference...\n",
    "# TODO(max): figure out closures...\n",
    "printMemrefF32_ = []\n",
    "\n",
    "\n",
    "@func\n",
    "def compute_linspace_val(ridx: T.index(), cidx: T.index(), stride_cidx: T.index()):\n",
    "    r = arith.index_cast(ridx, to=T.i32())\n",
    "    c = arith.index_cast(cidx, to=T.i32())\n",
    "    stride_c = arith.index_cast(stride_cidx, to=T.i32())\n",
    "    v2 = r * stride_c\n",
    "    v3 = c + v2\n",
    "    v4 = arith.sitofp(T.f16(), v3)\n",
    "    factor = arith.constant(64.0, T.f16())\n",
    "    v5 = arith.divf(v4, factor)\n",
    "    return v5\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_lhs_as_memref_32(lhs: T.memref(M, K, T.f16())):\n",
    "    M = memref.dim(lhs, 0)\n",
    "    K = memref.dim(lhs, 1)\n",
    "    tmp_alloc = memref.alloc((M, K), T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for k in range_(0, K):\n",
    "            f16 = lhs[m, k]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, k] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_rhs_as_memref_32(rhs: T.memref(K, N, T.f16())):\n",
    "    K = memref.dim(rhs, 0)\n",
    "    N = memref.dim(rhs, 1)\n",
    "    tmp_alloc = memref.alloc((K, N), T.f32())\n",
    "    for k in range_(0, K):\n",
    "        for n in range_(0, N):\n",
    "            f16 = rhs[k, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[k, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_res_as_memref_32(res: T.memref(M, N, T.f16())):\n",
    "    c0 = arith.constant(0, index=True)\n",
    "    c1 = arith.constant(1, index=True)\n",
    "    M = memref.dim(res, c0)\n",
    "    N = memref.dim(res, c1)\n",
    "    tmp_alloc = memref.alloc((M, N), T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for n in range_(0, N):\n",
    "            f16 = res[m, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def main():\n",
    "    lhs = memref.alloc((M, K), T.f16())\n",
    "    rhs = memref.alloc((K, N), T.f16())\n",
    "    res = memref.alloc((M, N), T.f16())\n",
    "\n",
    "    M_ = memref.dim(res, 0)\n",
    "    N_ = memref.dim(res, 1)\n",
    "    K_ = memref.dim(lhs, 1)\n",
    "\n",
    "    _f1 = arith.constant(1.0e00, T.f16())\n",
    "    _f0 = arith.constant(0.0e00, T.f16())\n",
    "    _c32 = arith.constant(32, T.index())\n",
    "\n",
    "    # Initialize the lhs matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, K_):\n",
    "            idx = compute_linspace_val(r, c, K_)\n",
    "            lhs[r, c] = idx\n",
    "\n",
    "    # Initialize the rhs matrix with a linspace function.\n",
    "    for r in range_(0, K_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            rhs[r, c] = idx\n",
    "\n",
    "    # Initialize the res matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            res[r, c] = idx\n",
    "\n",
    "    ulhs = memref.cast(T.memref(T.f16()), lhs)\n",
    "    urhs = memref.cast(T.memref(T.f16()), rhs)\n",
    "    ures = memref.cast(T.memref(T.f16()), res)\n",
    "    gpu.host_register(ulhs)\n",
    "    gpu.host_register(urhs)\n",
    "    gpu.host_register(ures)\n",
    "\n",
    "    print_lhs_as_memref_32(lhs)\n",
    "    print_rhs_as_memref_32(rhs)\n",
    "\n",
    "    @gpu.launch(grid_size=[1, 1, 1], block_size=[32, 1, 1])\n",
    "    def kernel(bx, by, bz, tx, ty, tz, *grid_block_sizes):\n",
    "        linalg.matmul(lhs, rhs, res)\n",
    "\n",
    "    print_res_as_memref_32(res)\n",
    "\n",
    "\n",
    "@builtin.module(attrs={\"transform.target_tag\": StringAttr.get(\"payload\")})\n",
    "def payload():\n",
    "    compute_linspace_val.emit()\n",
    "\n",
    "    @func\n",
    "    def printMemrefF32(x: T.memref(T.f32())):\n",
    "        ...\n",
    "\n",
    "    printMemrefF32_.append(printMemrefF32)\n",
    "\n",
    "    print_lhs_as_memref_32.emit()\n",
    "    print_rhs_as_memref_32.emit()\n",
    "    print_res_as_memref_32.emit()\n",
    "    main.emit()"
   ],
   "metadata": {
    "id": "7oQk4xJd72FI"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform schedule\n"
   ],
   "metadata": {
    "id": "a0vJZrpR74KB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@builtin.module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "def mod_transform():\n",
    "    @named_sequence(\n",
    "        \"main\", [any_op_t()], [], arg_attrs=[{\"transform.readonly\": UnitAttr.get()}]\n",
    "    )\n",
    "    def main(module: any_op_t()):\n",
    "        matmul = transform.match(module, [\"linalg.matmul\"])\n",
    "        transform.nvgpu.rewrite_matmul_as_mma_sync(matmul)\n",
    "        # clean up to simplify test below...\n",
    "        all_loops = transform.match(\n",
    "            module, interface=MatchInterfaceEnum.LoopLikeInterface\n",
    "        )\n",
    "        transform.apply_licm(all_loops)\n",
    "        transform.apply_cse(module)"
   ],
   "metadata": {
    "id": "EaBgGTIz72ci"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \"Finish\" the module"
   ],
   "metadata": {
    "id": "ADbabroS8ND2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "module = module.finish()\n",
    "print(module)\n",
    "assert module.operation.verify()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOsYXaW8QKC",
    "outputId": "f8592229-1d9b-4c52-9133-30fd52c2716d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute the transform schedule"
   ],
   "metadata": {
    "id": "0xN5kNvZ8Tyf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mod = run_pipeline(\n",
    "    module,\n",
    "    Pipeline().transform_interpreter(\n",
    "        entry_point=\"main\", debug_payload_root_tag=\"payload\"\n",
    "    ),\n",
    ")\n",
    "print(mod)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLwQLPD98Q4d",
    "outputId": "ecfa6c9a-15eb-40c7-df29-f43fcac02fbf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lower to NVVM (and LLVM)"
   ],
   "metadata": {
    "id": "D_NURglF8ZZW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CUDA_RUNTIME_EXISTS = Path(\"/usr/local/cuda\").exists()\n",
    "if CUDA_RUNTIME_EXISTS:\n",
    "    backend = LLVMJITBackend([CUDA_RUNTIME_LIB_PATH])\n",
    "    # this doesn't actually anything (no pipeline) but does generate C API/wrappers\n",
    "    compiled_module = backend.compile(\n",
    "        find_ops(\n",
    "            mod.operation,\n",
    "            lambda x: \"transform.target_tag\" in x.attributes\n",
    "                      and x.attributes[\"transform.target_tag\"].value == \"payload\",\n",
    "            single=True,\n",
    "        ),\n",
    "        Pipeline().add_pass(\n",
    "            \"gpu-lower-to-nvvm-pipeline\",\n",
    "            **{\n",
    "                \"cubin-chip\": \"sm_80\",\n",
    "                \"cubin-features\": \"+ptx76\",\n",
    "                \"cubin-format\": \"fatbin\",\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "    print(compiled_module)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IoWjgc48bcn",
    "outputId": "39550464-fd37-4e6d-a257-e803b746d8de"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and run"
   ],
   "metadata": {
    "id": "sOapyydH8n4h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if CUDA_RUNTIME_EXISTS:\n",
    "    backend.load(compiled_module).main_capi_wrapper()"
   ],
   "metadata": {
    "id": "pOEC4Qgw8p9X"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
