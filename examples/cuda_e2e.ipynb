{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Based on [transform-mma-sync-matmul-f16-f16-accum.mlir](https://github.com/llvm/llvm-project/blob/9cc2122bf5a81f7063c2a32b2cb78c8d615578a1/mlir/test/Integration/GPU/CUDA/TensorCore/sm80/transform-mma-sync-matmul-f16-f16-accum.mlir#L6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download mlir-python-bindings with CUDA support"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:48.337497Z",
     "start_time": "2025-05-05T16:40:48.251771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pip._internal.cli import cmdoptions\n",
    "from pip._internal.commands import index\n",
    "\n",
    "cmd = index.IndexCommand(\"blah\", \"\")\n",
    "\n",
    "options, args = cmd.parse_args(\n",
    "    [\n",
    "        \"index\",\n",
    "        \"versions\",\n",
    "        \"mlir-python-bindings\",\n",
    "        \"-f\",\n",
    "        \"https://makslevental.github.io/wheels\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_available_package_versions(self, options, args):\n",
    "    target_python = cmdoptions.make_target_python(options)\n",
    "    query = args[0]\n",
    "\n",
    "    with self._build_session(options) as session:\n",
    "        finder = self._build_package_finder(\n",
    "            options=options,\n",
    "            session=session,\n",
    "            target_python=target_python,\n",
    "            ignore_requires_python=options.ignore_requires_python,\n",
    "        )\n",
    "\n",
    "        versions = set(\n",
    "            candidate.version for candidate in finder.find_all_candidates(query)\n",
    "        )\n",
    "\n",
    "        return list(versions)\n",
    "\n",
    "\n",
    "def get_latest_cuda_version(all_versions):\n",
    "    cuda_versions = list(filter(lambda x: \"cuda\" in x.local, all_versions))\n",
    "    assert len(cuda_versions), \"couldn't find any cuda versions\"\n",
    "    cuda_versions.sort(key=lambda x: x.release)\n",
    "    return cuda_versions[0]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "all_versions = get_available_package_versions(cmd, options, [\"mlir-python-bindings\"])\n",
    "latest_cuda_version = get_latest_cuda_version(all_versions)\n",
    "!pip install -q mlir_python_bindings==$latest_cuda_version -f https://makslevental.github.io/wheels\n",
    "!pip install git+https://github.com/makslevental/mlir-python-extras@$BRANCH &> /dev/null"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xh-QUDWiX-FD",
    "outputId": "6865a63a-daa4-4610-e33a-721d37c0211f",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:49.887674Z",
     "start_time": "2025-05-05T16:40:48.379594Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Boilerplate"
   ],
   "metadata": {
    "id": "OSATAYhg7pSZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlir.extras.types as T\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects.transform import any_op_t\n",
    "from mlir.dialects.transform.extras import named_sequence\n",
    "from mlir.dialects.transform.structured import MatchInterfaceEnum\n",
    "from mlir.ir import StringAttr, UnitAttr\n",
    "\n",
    "from mlir import _mlir_libs\n",
    "from mlir.extras.ast.canonicalize import canonicalize\n",
    "from mlir.extras.context import RAIIMLIRContext, ExplicitlyManagedModule\n",
    "from mlir.extras.dialects.ext import arith, memref, scf, gpu\n",
    "from mlir.extras.dialects.ext import linalg\n",
    "from mlir.extras.dialects.ext import transform\n",
    "from mlir.extras.dialects.ext.func import func\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n",
    "from mlir.extras.util import find_ops\n",
    "\n",
    "CUDA_RUNTIME_LIB_PATH = Path(_mlir_libs.__file__).parent / f\"libmlir_cuda_runtime.so\"\n",
    "assert CUDA_RUNTIME_LIB_PATH.exists()"
   ],
   "metadata": {
    "id": "_R-_0M5ZYO8p",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.062103Z",
     "start_time": "2025-05-05T16:40:49.894599Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context"
   ],
   "metadata": {
    "id": "s-JTcrjo7tNK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ctx = RAIIMLIRContext()\n",
    "module = ExplicitlyManagedModule()"
   ],
   "metadata": {
    "id": "AGpWj9BzZLC_",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.072305Z",
     "start_time": "2025-05-05T16:40:50.068029Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kernel and helper code"
   ],
   "metadata": {
    "id": "qGcDtgkv71YB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "range_ = scf.range_\n",
    "\n",
    "M, K, N = 16, 16, 8\n",
    "\n",
    "# forward reference...\n",
    "# TODO(max): figure out closures...\n",
    "printMemrefF32_ = []\n",
    "\n",
    "\n",
    "@func\n",
    "def compute_linspace_val(ridx: T.index(), cidx: T.index(), stride_cidx: T.index()):\n",
    "    r = arith.index_cast(ridx, to=T.i32())\n",
    "    c = arith.index_cast(cidx, to=T.i32())\n",
    "    stride_c = arith.index_cast(stride_cidx, to=T.i32())\n",
    "    v2 = r * stride_c\n",
    "    v3 = c + v2\n",
    "    v4 = arith.sitofp(T.f16(), v3)\n",
    "    factor = arith.constant(64.0, T.f16())\n",
    "    v5 = arith.divf(v4, factor)\n",
    "    return v5\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_lhs_as_memref_32(lhs: T.memref(M, K, T.f16())):\n",
    "    M = memref.dim(lhs, 0)\n",
    "    K = memref.dim(lhs, 1)\n",
    "    tmp_alloc = memref.alloc((M, K), T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for k in range_(0, K):\n",
    "            f16 = lhs[m, k]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, k] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_rhs_as_memref_32(rhs: T.memref(K, N, T.f16())):\n",
    "    K = memref.dim(rhs, 0)\n",
    "    N = memref.dim(rhs, 1)\n",
    "    tmp_alloc = memref.alloc((K, N), T.f32())\n",
    "    for k in range_(0, K):\n",
    "        for n in range_(0, N):\n",
    "            f16 = rhs[k, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[k, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_res_as_memref_32(res: T.memref(M, N, T.f16())):\n",
    "    c0 = arith.constant(0, index=True)\n",
    "    c1 = arith.constant(1, index=True)\n",
    "    M = memref.dim(res, c0)\n",
    "    N = memref.dim(res, c1)\n",
    "    tmp_alloc = memref.alloc((M, N), T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for n in range_(0, N):\n",
    "            f16 = res[m, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def main():\n",
    "    lhs = memref.alloc((M, K), T.f16())\n",
    "    rhs = memref.alloc((K, N), T.f16())\n",
    "    res = memref.alloc((M, N), T.f16())\n",
    "\n",
    "    M_ = memref.dim(res, 0)\n",
    "    N_ = memref.dim(res, 1)\n",
    "    K_ = memref.dim(lhs, 1)\n",
    "\n",
    "    _f1 = arith.constant(1.0e00, T.f16())\n",
    "    _f0 = arith.constant(0.0e00, T.f16())\n",
    "    _c32 = arith.constant(32, T.index())\n",
    "\n",
    "    # Initialize the lhs matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, K_):\n",
    "            idx = compute_linspace_val(r, c, K_)\n",
    "            lhs[r, c] = idx\n",
    "\n",
    "    # Initialize the rhs matrix with a linspace function.\n",
    "    for r in range_(0, K_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            rhs[r, c] = idx\n",
    "\n",
    "    # Initialize the res matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            res[r, c] = idx\n",
    "\n",
    "    ulhs = memref.cast(T.memref(T.f16()), lhs)\n",
    "    urhs = memref.cast(T.memref(T.f16()), rhs)\n",
    "    ures = memref.cast(T.memref(T.f16()), res)\n",
    "    gpu.host_register(ulhs)\n",
    "    gpu.host_register(urhs)\n",
    "    gpu.host_register(ures)\n",
    "\n",
    "    print_lhs_as_memref_32(lhs)\n",
    "    print_rhs_as_memref_32(rhs)\n",
    "\n",
    "    @gpu.launch(grid_size=[1, 1, 1], block_size=[32, 1, 1])\n",
    "    def kernel(bx, by, bz, tx, ty, tz, *grid_block_sizes):\n",
    "        linalg.matmul(lhs, rhs, res)\n",
    "\n",
    "    print_res_as_memref_32(res)\n",
    "\n",
    "\n",
    "@builtin.module(attrs={\"transform.target_tag\": StringAttr.get(\"payload\")})\n",
    "def payload():\n",
    "    compute_linspace_val.emit()\n",
    "\n",
    "    @func\n",
    "    def printMemrefF32(x: T.memref(T.f32())):\n",
    "        ...\n",
    "\n",
    "    printMemrefF32_.append(printMemrefF32)\n",
    "\n",
    "    print_lhs_as_memref_32.emit()\n",
    "    print_rhs_as_memref_32.emit()\n",
    "    print_res_as_memref_32.emit()\n",
    "    main.emit()"
   ],
   "metadata": {
    "id": "7oQk4xJd72FI",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.228699Z",
     "start_time": "2025-05-05T16:40:50.112657Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform schedule\n"
   ],
   "metadata": {
    "id": "a0vJZrpR74KB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@builtin.module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "def mod_transform():\n",
    "    @named_sequence(\n",
    "        \"main\", [any_op_t()], [], arg_attrs=[{\"transform.readonly\": UnitAttr.get()}]\n",
    "    )\n",
    "    def main(module: any_op_t()):\n",
    "        matmul = transform.match(module, [\"linalg.matmul\"])\n",
    "        transform.nvgpu.rewrite_matmul_as_mma_sync(matmul)\n",
    "        # clean up to simplify test below...\n",
    "        all_loops = transform.match(\n",
    "            module, interface=MatchInterfaceEnum.LoopLikeInterface\n",
    "        )\n",
    "        transform.apply_licm(all_loops)\n",
    "        transform.apply_cse(module)"
   ],
   "metadata": {
    "id": "EaBgGTIz72ci",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.239377Z",
     "start_time": "2025-05-05T16:40:50.236219Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \"Finish\" the module"
   ],
   "metadata": {
    "id": "ADbabroS8ND2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "module = module.finish()\n",
    "print(module)\n",
    "assert module.operation.verify()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOsYXaW8QKC",
    "outputId": "f8592229-1d9b-4c52-9133-30fd52c2716d",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.286922Z",
     "start_time": "2025-05-05T16:40:50.284667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  module attributes {transform.target_tag = \"payload\"} {\n",
      "    func.func @compute_linspace_val(%arg0: index, %arg1: index, %arg2: index) -> f16 {\n",
      "      %0 = arith.index_cast %arg0 : index to i32\n",
      "      %1 = arith.index_cast %arg1 : index to i32\n",
      "      %2 = arith.index_cast %arg2 : index to i32\n",
      "      %3 = arith.muli %0, %2 : i32\n",
      "      %4 = arith.addi %1, %3 : i32\n",
      "      %5 = arith.sitofp %4 : i32 to f16\n",
      "      %cst = arith.constant 6.400000e+01 : f16\n",
      "      %6 = arith.divf %5, %cst : f16\n",
      "      return %6 : f16\n",
      "    }\n",
      "    func.func private @printMemrefF32(memref<*xf32>)\n",
      "    func.func @print_lhs_as_memref_32(%arg0: memref<16x16xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x16xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x16xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x16xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_rhs_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_res_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @main() {\n",
      "      %alloc = memref.alloc() : memref<16x16xf16>\n",
      "      %alloc_0 = memref.alloc() : memref<16x8xf16>\n",
      "      %alloc_1 = memref.alloc() : memref<16x8xf16>\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %alloc_1, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_2 = memref.dim %alloc_1, %c1 : memref<16x8xf16>\n",
      "      %c1_3 = arith.constant 1 : index\n",
      "      %dim_4 = memref.dim %alloc, %c1_3 : memref<16x16xf16>\n",
      "      %cst = arith.constant 1.000000e+00 : f16\n",
      "      %cst_5 = arith.constant 0.000000e+00 : f16\n",
      "      %c32 = arith.constant 32 : index\n",
      "      %c0_6 = arith.constant 0 : index\n",
      "      %c1_7 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_6 to %dim step %c1_7 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_4 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_4) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc[%arg0, %arg1] : memref<16x16xf16>\n",
      "        }\n",
      "      }\n",
      "      %c0_8 = arith.constant 0 : index\n",
      "      %c1_9 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_8 to %dim_4 step %c1_9 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_2 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_0[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %c0_10 = arith.constant 0 : index\n",
      "      %c1_11 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_10 to %dim step %c1_11 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_2 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_1[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<16x16xf16> to memref<*xf16>\n",
      "      %cast_12 = memref.cast %alloc_0 : memref<16x8xf16> to memref<*xf16>\n",
      "      %cast_13 = memref.cast %alloc_1 : memref<16x8xf16> to memref<*xf16>\n",
      "      gpu.host_register %cast : memref<*xf16>\n",
      "      gpu.host_register %cast_12 : memref<*xf16>\n",
      "      gpu.host_register %cast_13 : memref<*xf16>\n",
      "      call @print_lhs_as_memref_32(%alloc) : (memref<16x16xf16>) -> ()\n",
      "      call @print_rhs_as_memref_32(%alloc_0) : (memref<16x8xf16>) -> ()\n",
      "      %c1_14 = arith.constant 1 : index\n",
      "      %c1_15 = arith.constant 1 : index\n",
      "      %c1_16 = arith.constant 1 : index\n",
      "      %c32_17 = arith.constant 32 : index\n",
      "      %c1_18 = arith.constant 1 : index\n",
      "      %c1_19 = arith.constant 1 : index\n",
      "      gpu.launch blocks(%arg0, %arg1, %arg2) in (%arg6 = %c1_14, %arg7 = %c1_15, %arg8 = %c1_16) threads(%arg3, %arg4, %arg5) in (%arg9 = %c32_17, %arg10 = %c1_18, %arg11 = %c1_19) {\n",
      "        linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%alloc, %alloc_0 : memref<16x16xf16>, memref<16x8xf16>) outs(%alloc_1 : memref<16x8xf16>)\n",
      "        gpu.terminator\n",
      "      }\n",
      "      call @print_res_as_memref_32(%alloc_1) : (memref<16x8xf16>) -> ()\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "  module attributes {transform.with_named_sequence} {\n",
      "    transform.named_sequence @main(%arg0: !transform.any_op {transform.readonly}) {\n",
      "      %0 = transform.structured.match ops{[\"linalg.matmul\"]} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.nvgpu.rewrite_matmul_as_mma_sync %0 : (!transform.any_op) -> ()\n",
      "      %1 = transform.structured.match interface{LoopLikeInterface} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.apply_licm to %1 : !transform.any_op\n",
      "      transform.apply_cse to %arg0 : !transform.any_op\n",
      "      transform.yield \n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute the transform schedule"
   ],
   "metadata": {
    "id": "0xN5kNvZ8Tyf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mod = run_pipeline(\n",
    "    module,\n",
    "    Pipeline().transform_interpreter(\n",
    "        entry_point=\"main\", debug_payload_root_tag=\"payload\"\n",
    "    ),\n",
    ")\n",
    "print(mod)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLwQLPD98Q4d",
    "outputId": "ecfa6c9a-15eb-40c7-df29-f43fcac02fbf",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.337714Z",
     "start_time": "2025-05-05T16:40:50.332516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#map = affine_map<()[s0] -> (s0 floordiv 4)>\n",
      "#map1 = affine_map<()[s0] -> (s0 * 2 - (s0 floordiv 4) * 8)>\n",
      "#map2 = affine_map<()[s0] -> (s0 * 2 - (s0 floordiv 4) * 8 + 1)>\n",
      "#map3 = affine_map<()[s0] -> (s0 floordiv 4 + 8)>\n",
      "#map4 = affine_map<()[s0] -> (s0 * 2 - (s0 floordiv 4) * 8 + 8)>\n",
      "#map5 = affine_map<()[s0] -> (s0 * 2 - (s0 floordiv 4) * 8 + 9)>\n",
      "module {\n",
      "  module attributes {transform.target_tag = \"payload\"} {\n",
      "    func.func @compute_linspace_val(%arg0: index, %arg1: index, %arg2: index) -> f16 {\n",
      "      %0 = arith.index_cast %arg0 : index to i32\n",
      "      %1 = arith.index_cast %arg1 : index to i32\n",
      "      %2 = arith.index_cast %arg2 : index to i32\n",
      "      %3 = arith.muli %0, %2 : i32\n",
      "      %4 = arith.addi %1, %3 : i32\n",
      "      %5 = arith.sitofp %4 : i32 to f16\n",
      "      %cst = arith.constant 6.400000e+01 : f16\n",
      "      %6 = arith.divf %5, %cst : f16\n",
      "      return %6 : f16\n",
      "    }\n",
      "    func.func private @printMemrefF32(memref<*xf32>)\n",
      "    func.func @print_lhs_as_memref_32(%arg0: memref<16x16xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x16xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x16xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x16xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_rhs_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_res_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @main() {\n",
      "      %alloc = memref.alloc() : memref<16x16xf16>\n",
      "      %alloc_0 = memref.alloc() : memref<16x8xf16>\n",
      "      %alloc_1 = memref.alloc() : memref<16x8xf16>\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %alloc_1, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_2 = memref.dim %alloc_1, %c1 : memref<16x8xf16>\n",
      "      %dim_3 = memref.dim %alloc, %c1 : memref<16x16xf16>\n",
      "      scf.for %arg0 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_3 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_3) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc[%arg0, %arg1] : memref<16x16xf16>\n",
      "        }\n",
      "      }\n",
      "      scf.for %arg0 = %c0 to %dim_3 step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_2 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_0[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      scf.for %arg0 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_2 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_1[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<16x16xf16> to memref<*xf16>\n",
      "      %cast_4 = memref.cast %alloc_0 : memref<16x8xf16> to memref<*xf16>\n",
      "      %cast_5 = memref.cast %alloc_1 : memref<16x8xf16> to memref<*xf16>\n",
      "      gpu.host_register %cast : memref<*xf16>\n",
      "      gpu.host_register %cast_4 : memref<*xf16>\n",
      "      gpu.host_register %cast_5 : memref<*xf16>\n",
      "      call @print_lhs_as_memref_32(%alloc) : (memref<16x16xf16>) -> ()\n",
      "      call @print_rhs_as_memref_32(%alloc_0) : (memref<16x8xf16>) -> ()\n",
      "      %c32 = arith.constant 32 : index\n",
      "      gpu.launch blocks(%arg0, %arg1, %arg2) in (%arg6 = %c1, %arg7 = %c1, %arg8 = %c1) threads(%arg3, %arg4, %arg5) in (%arg9 = %c32, %arg10 = %c1, %arg11 = %c1) {\n",
      "        %thread_id_x = gpu.thread_id  x\n",
      "        %0 = affine.apply #map()[%thread_id_x]\n",
      "        %1 = affine.apply #map1()[%thread_id_x]\n",
      "        %2 = memref.load %alloc[%0, %1] : memref<16x16xf16>\n",
      "        %3 = affine.apply #map2()[%thread_id_x]\n",
      "        %4 = memref.load %alloc[%0, %3] : memref<16x16xf16>\n",
      "        %5 = affine.apply #map3()[%thread_id_x]\n",
      "        %6 = memref.load %alloc[%5, %1] : memref<16x16xf16>\n",
      "        %7 = memref.load %alloc[%5, %3] : memref<16x16xf16>\n",
      "        %8 = affine.apply #map4()[%thread_id_x]\n",
      "        %9 = memref.load %alloc[%0, %8] : memref<16x16xf16>\n",
      "        %10 = affine.apply #map5()[%thread_id_x]\n",
      "        %11 = memref.load %alloc[%0, %10] : memref<16x16xf16>\n",
      "        %12 = memref.load %alloc[%5, %8] : memref<16x16xf16>\n",
      "        %13 = memref.load %alloc[%5, %10] : memref<16x16xf16>\n",
      "        %14 = vector.splat %2 : vector<4x2xf16>\n",
      "        %15 = vector.insert %2, %14 [0, 0] : f16 into vector<4x2xf16>\n",
      "        %16 = vector.insert %4, %15 [0, 1] : f16 into vector<4x2xf16>\n",
      "        %17 = vector.insert %6, %16 [1, 0] : f16 into vector<4x2xf16>\n",
      "        %18 = vector.insert %7, %17 [1, 1] : f16 into vector<4x2xf16>\n",
      "        %19 = vector.insert %9, %18 [2, 0] : f16 into vector<4x2xf16>\n",
      "        %20 = vector.insert %11, %19 [2, 1] : f16 into vector<4x2xf16>\n",
      "        %21 = vector.insert %12, %20 [3, 0] : f16 into vector<4x2xf16>\n",
      "        %22 = vector.insert %13, %21 [3, 1] : f16 into vector<4x2xf16>\n",
      "        %23 = memref.load %alloc_0[%1, %0] : memref<16x8xf16>\n",
      "        %24 = memref.load %alloc_0[%3, %0] : memref<16x8xf16>\n",
      "        %25 = memref.load %alloc_0[%8, %0] : memref<16x8xf16>\n",
      "        %26 = memref.load %alloc_0[%10, %0] : memref<16x8xf16>\n",
      "        %27 = vector.splat %23 : vector<2x2xf16>\n",
      "        %28 = vector.insert %23, %27 [0, 0] : f16 into vector<2x2xf16>\n",
      "        %29 = vector.insert %24, %28 [0, 1] : f16 into vector<2x2xf16>\n",
      "        %30 = vector.insert %25, %29 [1, 0] : f16 into vector<2x2xf16>\n",
      "        %31 = vector.insert %26, %30 [1, 1] : f16 into vector<2x2xf16>\n",
      "        %32 = memref.load %alloc_1[%0, %1] : memref<16x8xf16>\n",
      "        %33 = memref.load %alloc_1[%0, %3] : memref<16x8xf16>\n",
      "        %34 = memref.load %alloc_1[%5, %1] : memref<16x8xf16>\n",
      "        %35 = memref.load %alloc_1[%5, %3] : memref<16x8xf16>\n",
      "        %36 = vector.splat %32 : vector<2x2xf16>\n",
      "        %37 = vector.insert %32, %36 [0, 0] : f16 into vector<2x2xf16>\n",
      "        %38 = vector.insert %33, %37 [0, 1] : f16 into vector<2x2xf16>\n",
      "        %39 = vector.insert %34, %38 [1, 0] : f16 into vector<2x2xf16>\n",
      "        %40 = vector.insert %35, %39 [1, 1] : f16 into vector<2x2xf16>\n",
      "        %41 = nvgpu.mma.sync(%22, %31, %40) {mmaShape = [16, 8, 16]} : (vector<4x2xf16>, vector<2x2xf16>, vector<2x2xf16>) -> vector<2x2xf16>\n",
      "        %42 = vector.extract %41[0, 0] : f16 from vector<2x2xf16>\n",
      "        %43 = vector.extract %41[0, 1] : f16 from vector<2x2xf16>\n",
      "        %44 = vector.extract %41[1, 0] : f16 from vector<2x2xf16>\n",
      "        %45 = vector.extract %41[1, 1] : f16 from vector<2x2xf16>\n",
      "        memref.store %42, %alloc_1[%0, %1] : memref<16x8xf16>\n",
      "        memref.store %43, %alloc_1[%0, %3] : memref<16x8xf16>\n",
      "        memref.store %44, %alloc_1[%5, %1] : memref<16x8xf16>\n",
      "        memref.store %45, %alloc_1[%5, %3] : memref<16x8xf16>\n",
      "        gpu.terminator\n",
      "      }\n",
      "      call @print_res_as_memref_32(%alloc_1) : (memref<16x8xf16>) -> ()\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "  module attributes {transform.with_named_sequence} {\n",
      "    transform.named_sequence @main(%arg0: !transform.any_op {transform.readonly}) {\n",
      "      %0 = transform.structured.match ops{[\"linalg.matmul\"]} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.nvgpu.rewrite_matmul_as_mma_sync %0 : (!transform.any_op) -> ()\n",
      "      %1 = transform.structured.match interface{LoopLikeInterface} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.apply_licm to %1 : !transform.any_op\n",
      "      transform.apply_cse to %arg0 : !transform.any_op\n",
      "      transform.yield \n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lower to NVVM (and LLVM)"
   ],
   "metadata": {
    "id": "D_NURglF8ZZW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CUDA_RUNTIME_EXISTS = Path(\"/usr/local/cuda\").exists()\n",
    "if CUDA_RUNTIME_EXISTS:\n",
    "    backend = LLVMJITBackend([CUDA_RUNTIME_LIB_PATH])\n",
    "    # this doesn't actually anything (no pipeline) but does generate C API/wrappers\n",
    "    compiled_module = backend.compile(\n",
    "        find_ops(\n",
    "            mod.operation,\n",
    "            lambda x: \"transform.target_tag\" in x.attributes\n",
    "                      and x.attributes[\"transform.target_tag\"].value == \"payload\",\n",
    "            single=True,\n",
    "        ),\n",
    "        Pipeline().add_pass(\n",
    "            \"gpu-lower-to-nvvm-pipeline\",\n",
    "            **{\n",
    "                \"cubin-chip\": \"sm_80\",\n",
    "                \"cubin-features\": \"+ptx76\",\n",
    "                \"cubin-format\": \"fatbin\",\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "    print(compiled_module)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IoWjgc48bcn",
    "outputId": "39550464-fd37-4e6d-a257-e803b746d8de",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.384882Z",
     "start_time": "2025-05-05T16:40:50.382923Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and run"
   ],
   "metadata": {
    "id": "sOapyydH8n4h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if CUDA_RUNTIME_EXISTS:\n",
    "    backend.load(compiled_module).main_capi_wrapper()"
   ],
   "metadata": {
    "id": "pOEC4Qgw8p9X",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:40:50.431171Z",
     "start_time": "2025-05-05T16:40:50.429818Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  }
 ]
}
